# Heuristics Considered Harmful: RL With Random Rewards Should Not Make LLMs Reason

This is the code for the blog post [Heuristics Considered Harmful: RL With Random Rewards Should Not Make LLMs Reason](https://www.notion.so/Heuristics-Considered-Harmful-RL-With-Random-Rewards-Should-Not-Make-LLMs-Reason-21ba29497c4180ca86ffce303f01923d).

We used the [verl](https://github.com/volcengine/verl) library to train the model and the installation is the same as the verl library.

## Training
To reproduce our results, you can run the following command:
```bash
python run_random_rewards.py
```

We tested the 'random_rewards' and 'normal' reward types.

Data can be generated by running the `examples/data_preprocess/math_dataset.py` script.

## Citation
If you find this work useful, please cite:
```bibtex
@misc{oertell2025heuristicsconsideredharmful,
      title={Heuristics Considered Harmful: RL With Random Rewards Should Not Make LLMs Reason}, 
      author={Owen Oertell and Wenhao Zhao and Gokul Swamy and Zhiwei Steven Wu and Kiante Brantley and Jason Lee and Wen Sun},
      year={2025},
      url={https://www.notion.so/Heuristics-Considered-Harmful-RL-With-Random-Rewards-Should-Not-Make-LLMs-Reason-21ba29497c4180ca86ffce303f01923d}, 
}
```